{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Collection for the model\n",
    "\n",
    "# import python libraries\n",
    "import cv2\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "# Create a VideoCapture object\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = HandDetector(maxHands=1)\n",
    "\n",
    "# size of the image\n",
    "offset = 20\n",
    "imgSize = 300\n",
    "\n",
    "# Change folder name for each new gesture\n",
    "folder = \"mydata/A\"\n",
    "counter = 0\n",
    "\n",
    "# Run this until the program is stopped\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    success, img = cap.read()\n",
    "    hands, img = detector.findHands(img)\n",
    "    # Get hand information\n",
    "    if hands:\n",
    "        hand = hands[0]\n",
    "        x, y, w, h = hand['bbox']\n",
    "\n",
    "        imgWhite = np.ones((imgSize, imgSize, 3), np.uint8) * 255\n",
    "        imgCrop = img[y - offset:y + h + offset, x - offset:x + w + offset]\n",
    "\n",
    "        # Check if imgCrop is not empty before processing\n",
    "        if not imgCrop.size == 0:\n",
    "            imgCropShape = imgCrop.shape\n",
    "\n",
    "            # check if the image is portrait or landscape\n",
    "            aspectRatio = h / w\n",
    "            if aspectRatio > 1:\n",
    "                k = imgSize / h\n",
    "                wCal = math.ceil(k * w)\n",
    "                imgResize = cv2.resize(imgCrop, (wCal, imgSize))\n",
    "                imgResizeShape = imgResize.shape\n",
    "                wGap = math.ceil((imgSize - wCal) / 2)\n",
    "                imgWhite[:, wGap:wCal + wGap] = imgResize\n",
    "\n",
    "            else:\n",
    "                k = imgSize / w\n",
    "                hCal = math.ceil(k * h)\n",
    "                imgResize = cv2.resize(imgCrop, (imgSize, hCal))\n",
    "                imgResizeShape = imgResize.shape\n",
    "                hGap = math.ceil((imgSize - hCal) / 2)\n",
    "                imgWhite[hGap:hCal + hGap, :] = imgResize\n",
    "\n",
    "            # Show the diffrent frames\n",
    "            cv2.imshow(\"ImageCrop\", imgCrop)\n",
    "            cv2.imshow(\"Image\", imgWhite)\n",
    "\n",
    "    cv2.imshow(\"Camera\", img)\n",
    "    key = cv2.waitKey(1)\n",
    "\n",
    "    # Inside the loop, before saving the image\n",
    "    if key == ord(\"s\"):\n",
    "        counter += 1\n",
    "        filename = f'{folder}/img_{time.time()}.jpg'\n",
    "        cv2.imwrite(filename, imgWhite)\n",
    "        print(f\"Saved image {counter} as {filename}\")\n",
    "        \n",
    "    # Press q to quit\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "# Destroy the window\n",
    "cv2.destroyWindow('Camera')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Model Code\n",
    "\n",
    "# import python libraries\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "from cvzone.HandTrackingModule import HandDetector\n",
    "from cvzone.ClassificationModule import Classifier\n",
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "from PIL import Image, ImageTk\n",
    "import time\n",
    "import pyperclip\n",
    "\n",
    "# Create a classifier object\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = HandDetector(maxHands=1)\n",
    "classifier = Classifier(\"keras_model.h5\", \"labels.txt\")\n",
    "labels = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\",\n",
    "          \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\", \".\", \" \", \"/\"]\n",
    "\n",
    "# Take size of the image\n",
    "offset = 20\n",
    "imgSize = 300\n",
    "time_delay = 3  # 3 seconds delay\n",
    "last_time = time.time()\n",
    "\n",
    "# Function to copy text to clipboard\n",
    "def copy_text_to_clipboard():\n",
    "    text = text_editor.get(\"1.0\", \"end-1c\")\n",
    "    pyperclip.copy(text)\n",
    "\n",
    "# Function to clear text\n",
    "def clear_text():\n",
    "    text_editor.delete(\"1.0\", tk.END)\n",
    "\n",
    "# Function to update the video frame\n",
    "def update_frame():\n",
    "    global last_time\n",
    "\n",
    "    success, img = cap.read()\n",
    "    imgOutput = img.copy()\n",
    "\n",
    "    hands, img = detector.findHands(img)\n",
    "    if hands:\n",
    "        arr = ['*', '*']\n",
    "        hand = hands[0]\n",
    "        x, y, w, h = hand['bbox']\n",
    "\n",
    "        imgWhite = np.ones((imgSize, imgSize, 3), np.uint8) * 255\n",
    "        imgCrop = img[y - offset:y + h + offset, x - offset:x + w + offset]\n",
    "\n",
    "        # Check if imgCrop is empty\n",
    "        if not imgCrop.size:\n",
    "            return\n",
    "        imgCropShape = imgCrop.shape\n",
    "\n",
    "        # Check if the image is portrait or landscape\n",
    "        aspectRatio = h / w\n",
    "        if aspectRatio > 1:\n",
    "            k = imgSize / h\n",
    "            wCal = math.ceil(k * w)\n",
    "            imgResize = cv2.resize(imgCrop, (wCal, imgSize))\n",
    "            imgResizeShape = imgResize.shape\n",
    "            wGap = math.ceil((imgSize - wCal) / 2)\n",
    "            imgWhite[:, wGap:wCal + wGap] = imgResize\n",
    "            prediction, index = classifier.getPrediction(imgWhite, draw=False)\n",
    "\n",
    "        else:\n",
    "            k = imgSize / w\n",
    "            hCal = math.ceil(k * h)\n",
    "            imgResize = cv2.resize(imgCrop, (imgSize, hCal))\n",
    "            imgResizeShape = imgResize.shape\n",
    "            hGap = math.ceil((imgSize - hCal) / 2)\n",
    "            imgWhite[hGap:hCal + hGap, :] = imgResize\n",
    "            prediction, index = classifier.getPrediction(imgWhite, draw=False)\n",
    "\n",
    "        # Display the prediction and the letter\n",
    "        prediction = round(prediction[index]*100, 2)\n",
    "        print('Percentage: ', prediction)\n",
    "        print('Letter: ', labels[index])\n",
    "\n",
    "        # Draw the bounding box and the letter on the video feed\n",
    "        cv2.rectangle(imgOutput, (x - offset, y - offset - 50),\n",
    "                      (x + w + offset, y - offset), (255, 0, 255), cv2.FILLED)\n",
    "        cv2.putText(imgOutput, labels[index]+' ('+str(prediction)+')%', (x, y - 26),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 1.0, (255, 255, 255), 2)\n",
    "        cv2.rectangle(imgOutput, (x - offset, y - offset),\n",
    "                      (x + w + offset, y + h + offset), (255, 0, 255), 4)\n",
    "\n",
    "        # Check if the letter is the same as the previous letter then add it to the text editor\n",
    "        current_time = time.time()\n",
    "        if current_time - last_time > time_delay:\n",
    "            arr.pop(0)\n",
    "            arr.append(labels[index])\n",
    "\n",
    "            if arr[1] != '*' and arr[0] != arr[1]:\n",
    "                if arr[1] == '/':\n",
    "                    text_editor.delete(tk.END + \"-2c\", tk.END)\n",
    "                else:\n",
    "                    text_editor.insert(tk.END, arr[1])\n",
    "            last_time = current_time\n",
    "\n",
    "    # Display the video feed\n",
    "    img_output = cv2.cvtColor(imgOutput, cv2.COLOR_BGR2RGB)\n",
    "    img_output = cv2.resize(img_output, (640, 480))\n",
    "    photo = ImageTk.PhotoImage(image=Image.fromarray(img_output))\n",
    "    video_label.config(image=photo)\n",
    "    video_label.image = photo\n",
    "\n",
    "    # Update the frame after 10 milliseconds\n",
    "    root.after(10, update_frame)\n",
    "\n",
    "\n",
    "# Create a tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Smart Text Editor For Sign Language Users\")\n",
    "\n",
    "# Create a frame for the video feed\n",
    "video_frame = tk.Frame(root)\n",
    "video_frame.pack(side=tk.LEFT)\n",
    "\n",
    "# Create a label to display the video feed\n",
    "video_label = tk.Label(video_frame)\n",
    "video_label.pack()\n",
    "\n",
    "# Create a frame for the text editor\n",
    "text_frame = tk.Frame(root)\n",
    "text_frame.pack(side=tk.RIGHT)\n",
    "\n",
    "# Create a text editor\n",
    "text_editor = scrolledtext.ScrolledText(text_frame, wrap=tk.WORD)\n",
    "text_editor.pack()\n",
    "\n",
    "# Create a \"Copy Text\" button\n",
    "copy_button = tk.Button(text_frame, text=\"Copy Text\",\n",
    "                        command=copy_text_to_clipboard)\n",
    "copy_button.pack()\n",
    "\n",
    "# Create a \"Clear Text\" button\n",
    "clear_button = tk.Button(text_frame, text=\"Clear Text\", command=clear_text)\n",
    "clear_button.pack()\n",
    "\n",
    "# Start updating the video frame\n",
    "update_frame()\n",
    "\n",
    "# Run the tkinter main loop\n",
    "root.mainloop()\n",
    "\n",
    "# Release the webcam when the application is closed\n",
    "cap.release()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
